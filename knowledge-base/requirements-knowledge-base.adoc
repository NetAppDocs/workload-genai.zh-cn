---
sidebar: sidebar 
permalink: knowledge-base/requirements-knowledge-base.html 
keywords: ai, chatbot, prerequisites, bedrock, fsx for ontap, prerequisites, requirements 
summary: 在构建知识库之前，请确保 Workload Factory 和 AWS 已正确设置。这包括拥有您的 AWS 登录凭证、已部署的 FSx for ONTAP文件系统（其中包含您想要集成到知识库中的数据源）、访问 Amazon Bedrock AI 服务等等。 
---
= GenAI知识库要求
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
在构建知识库之前，请确保 Workload Factory 和 AWS 已正确设置。这包括拥有您的 AWS 登录凭证、已部署的 FSx for ONTAP文件系统（其中包含您想要集成到知识库中的数据源）、访问 Amazon Bedrock AI 服务等等。



== 基本GenAI要求

GenAI具有您的环境在开始使用之前需要满足的一般要求。

工作负载工厂登录和帐户:: 你需要 https://docs.netapp.com/us-en/workload-setup-admin/sign-up-saas.html["在 Workload Factory 上创建一个帐户"^]并使用以下任一方式登录 https://docs.netapp.com/us-en/workload-setup-admin/console-experiences.html["控制台体验"^]。
AWS 凭据和权限:: 您需要将具有读/写权限的 AWS 凭证添加到 Workload Factory，这意味着您将以读/写模式使用 Workload Factory 进行 GenAI。
+
--
目前不支持_Basic_模式和_read-only _模式权限。

设置凭据时、选择如下所示的权限后、您将拥有管理FSx for ONTAP文件系统以及部署和管理GenAI EC2实例以及知识库和聊天机器人所需的其他AWS资源的完全访问权限。

https://docs.netapp.com/us-en/workload-setup-admin/add-credentials.html["了解如何将 AWS 凭证添加到 Workload Factory"^]

--




== GenAI知识库要求

如果您计划使用知识库、请确保您的环境满足以下要求。

亚马逊基岩:: Amazon Brock使您能够使用基础模型、并提供构建生成性AI应用程序的功能。
+
--
在开始使用NetApp Workload Factory for GenAI 之前，您必须设置 Amazon Bedrock。您的 GenAI 部署必须位于启用了 Amazon Bedrock 的 AWS 区域。

* https://docs.aws.amazon.com/bedrock/latest/userguide/setting-up.html["AWS文档：设置Amazon Brock"^]
* https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-supported.html["AWS文档：Amazon Brock知识库支持的区域和型号"^]


默认情况下、GenAI会重新排列搜索结果、以提高结果相关性。为了获得最佳结果、请确保您的Amazon基岩基础模型配置包含对重新排序模型的访问权限、例如Cohere Rerank或Amazon Rerank (如果您所在地区有)。

--
嵌入模型:: 在创建知识库之前、您必须启用计划使用的嵌入模型。支持以下嵌入模型：
+
--
* T人 嵌入G1 -文本
* T人 嵌入文本v2
* 第1代多模态嵌入
* 嵌入英语
* 嵌入多语言
+
https://aws.amazon.com/bedrock/titan/["详细了解Amazon大力孙"^]



--
聊天模式:: 在创建知识库之前、您必须启用计划使用的基本聊天模式。由于型号支持因AWS地区而异、请参见 https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html["AWS文档"^] 以验证您可以在计划部署知识库的地区使用哪些型号。
+
--
GenAI支持各种型号、包括Anthropic、Amazon、Mistral AI、Meta、JAMBA和cothere。

详细了解如何在Amazon Brock中使用这些模型：

* https://aws.amazon.com/bedrock/claude/["anthpic的克洛德在亚马逊基岩"^]
* https://docs.aws.amazon.com/nova/latest/userguide/getting-started-console.html["在Amazon B基石 控制台中开始使用Amazon Nova"^]
* https://aws.amazon.com/bedrock/mistral/["Mistral AI型号"^]
* https://docs.aws.amazon.com/bedrock/latest/userguide/titan-text-models.html["Amazon T人 文本模型"^]
* https://aws.amazon.com/bedrock/llama/["Meta Llama模型"^]
* https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-jamba.html["JAMBA型号"^]
* https://aws.amazon.com/bedrock/cohere/["Cohere命令模型"^]


--
FSx for ONTAP文件系统:: 对于ONTAP文件系统、至少需要一个FSx：
+
--
* NetApp GenAI引擎将使用一个文件系统(如果不存在、则创建一个文件系统)来存储知识库使用的矢量数据库。
+
此FSx for ONTAP文件系统必须使用FlexVol卷。不支持 FlexGroup 卷。

* 一个或多个文件系统将包含要集成到知识库中的数据源。
+
一个FSx for ONTAP文件系统可同时用于这两种用途、也可以使用多个FSx for ONTAP文件系统。

* 您需要了解AWS FSx for ONTAP文件系统所在的AWS区域、VPC和子网。文件系统必须位于已启用Amazon Brock的AWS区域中。
* 您需要考虑要应用于此部署中的AWS资源的标记键/值对(可选)。
* 您需要知道密钥对信息、以便安全地连接到NetApp AI引擎实例。


https://docs.netapp.com/us-en/workload-fsx-ontap/create-file-system.html["了解如何部署和管理FSx for ONTAP文件系统"^]

--

